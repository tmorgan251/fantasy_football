{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e8767499",
   "metadata": {},
   "outputs": [],
   "source": [
    "# ============================================================\n",
    "# ESPN Fantasy Draft Value Project (Re-ordered, end-to-end)\n",
    "# - Block-by-block, in a logical pipeline\n",
    "# - Separates: (A) hygiene + load, (B) league-year filtering,\n",
    "#              (C) enrichment, (D) optimal lineup valid points,\n",
    "#              (E) autodraft baseline + scoring, (F) plots\n",
    "# - Adds: scoring-rule filter using anchor players\n",
    "# ============================================================\n",
    "\n",
    "from __future__ import annotations\n",
    "\n",
    "from pathlib import Path\n",
    "import re\n",
    "import time\n",
    "\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "373b0fad",
   "metadata": {},
   "outputs": [],
   "source": [
    "# ============================================================\n",
    "# BLOCK 0 — CONFIG\n",
    "# ============================================================\n",
    "\n",
    "RAW_BASE = Path(\"data/raw/espn\")                  # expects subfolders like 2021/, 2022/, ...\n",
    "OUT_DIR  = Path(\"data/preprocessed\")\n",
    "OUT_DIR.mkdir(parents=True, exist_ok=True)\n",
    "\n",
    "YEARS = range(2021, 2025)                         # your current dataset range\n",
    "RAW_FILES = [\"lineup_data.csv\", \"draft_data.csv\", \"transaction_data.csv\"]\n",
    "\n",
    "EXPECTED_STARTERS = {\"QB\":1,\"RB\":2,\"WR\":2,\"TE\":1,\"FLEX\":1,\"K\":1,\"D/ST\":1,\"OP\":0,\"STARTERS\":9}\n",
    "EXPECTED_DRAFT_LENGTH = 160\n",
    "\n",
    "# \"Anchor players\" for scoring-rule detection:\n",
    "# pick players that appear most seasons + are usually drafted/rostered.\n",
    "# You can tune these later.\n",
    "ANCHORS_BY_POS = {\n",
    "    \"QB\":  [\"Josh Allen\", \"Patrick Mahomes\"],\n",
    "    \"RB\":  [\"Christian McCaffrey\", \"Derrick Henry\"],\n",
    "    \"WR\":  [\"Justin Jefferson\", \"Tyreek Hill\"],\n",
    "    \"TE\":  [\"Travis Kelce\", \"Mark Andrews\"],\n",
    "    \"K\":   [\"Justin Tucker\"],\n",
    "    \"D/ST\":[\"Patriots D/ST\", \"49ers D/ST\", \"Cowboys D/ST\"],  # depends on naming in your data\n",
    "}\n",
    "# If anchor names don’t match your dataset strings, add synonyms below.\n",
    "ANCHOR_SYNONYMS = {\n",
    "    # \"New England Patriots\": \"Patriots D/ST\",\n",
    "    # \"San Francisco 49ers\": \"49ers D/ST\",\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cbd0962c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# ============================================================\n",
    "# BLOCK 1 — RAW FILE HYGIENE: DROP DUPLICATE ROWS IN EACH YEAR CSV\n",
    "# ============================================================\n",
    "\n",
    "def drop_raw_duplicates_in_place(base_dir: Path, years, files) -> None:\n",
    "    for year in years:\n",
    "        print(f\"\\n=== YEAR {year} ===\")\n",
    "        year_dir = base_dir / str(year)\n",
    "\n",
    "        for fname in files:\n",
    "            path = year_dir / fname\n",
    "            if not path.exists():\n",
    "                print(f\"  {fname}: missing\")\n",
    "                continue\n",
    "\n",
    "            df = pd.read_csv(path)\n",
    "            before = len(df)\n",
    "            df2 = df.drop_duplicates()\n",
    "            after = len(df2)\n",
    "            dropped = before - after\n",
    "\n",
    "            if dropped == 0:\n",
    "                print(f\"  {fname}: no duplicates ({before:,} rows)\")\n",
    "            else:\n",
    "                df2.to_csv(path, index=False)\n",
    "                print(f\"  {fname}: dropped {dropped:,} duplicate rows ({before:,} → {after:,})\")\n",
    "\n",
    "\n",
    "# Run once (safe to re-run)\n",
    "drop_raw_duplicates_in_place(RAW_BASE, YEARS, RAW_FILES)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fb77344e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# ============================================================\n",
    "# BLOCK 2 — NORMALIZATION HELPERS\n",
    "# ============================================================\n",
    "\n",
    "CORE_POS = {\"QB\", \"RB\", \"WR\", \"TE\", \"K\", \"D/ST\", \"DST\", \"DEF\"}\n",
    "\n",
    "def normalize_player_name(name: str) -> str:\n",
    "    if pd.isna(name):\n",
    "        return name\n",
    "    s = str(name).strip()\n",
    "    s = re.sub(r\"\\s+\", \" \", s)\n",
    "    s = s.replace(\" Jr.\", \"\").replace(\" Sr.\", \"\")\n",
    "    # apply anchor synonyms (optional)\n",
    "    s = ANCHOR_SYNONYMS.get(s, s)\n",
    "    return s\n",
    "\n",
    "def normalize_slot(slot: str) -> str:\n",
    "    s = str(slot).strip().upper()\n",
    "    if s in {\"DST\", \"DEF\", \"D/ST\"}:\n",
    "        return \"D/ST\"\n",
    "    if s in {\"BE\", \"BENCH\"}:\n",
    "        return \"BE\"\n",
    "    if s in {\"IR\"}:\n",
    "        return \"IR\"\n",
    "    if s in {\"RB/WR/TE\", \"FLEX\"}:\n",
    "        return \"FLEX\"\n",
    "    if s in {\"OP\", \"SUPERFLEX\", \"QB/RB/WR/TE\"}:\n",
    "        return \"OP\"\n",
    "    return s"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5bea89b3",
   "metadata": {},
   "outputs": [],
   "source": [
    "# ============================================================\n",
    "# BLOCK 3 — LOADERS (multi-season draft + lineups)\n",
    "# ============================================================\n",
    "\n",
    "def load_draft(path: Path, year: int) -> pd.DataFrame:\n",
    "    df = pd.read_csv(path)\n",
    "    required = [\"League_ID\",\"Player\",\"Team\",\"Round\",\"Pick\",\"Overall\",\"Is_Autodrafted\",\"Auto_Draft_Type_ID\"]\n",
    "    missing = [c for c in required if c not in df.columns]\n",
    "    if missing:\n",
    "        raise ValueError(f\"{path} draft_data is missing columns: {missing}\")\n",
    "\n",
    "    df = df.copy()\n",
    "    df[\"Year\"] = int(year)\n",
    "    df[\"Player_norm\"] = df[\"Player\"].map(normalize_player_name)\n",
    "    df[\"League_ID\"] = df[\"League_ID\"].astype(int)\n",
    "    df[\"Year\"] = df[\"Year\"].astype(int)\n",
    "    df[\"Overall\"] = pd.to_numeric(df[\"Overall\"], errors=\"coerce\")\n",
    "    df[\"Is_Autodrafted\"] = pd.to_numeric(df[\"Is_Autodrafted\"], errors=\"coerce\").fillna(0).astype(int)\n",
    "    return df\n",
    "\n",
    "def load_lineups(path: Path, year: int) -> pd.DataFrame:\n",
    "    df = pd.read_csv(path)\n",
    "    required = [\"League_ID\",\"Week\",\"Team\",\"Player\",\"Slot\",\"Points\"]\n",
    "    missing = [c for c in required if c not in df.columns]\n",
    "    if missing:\n",
    "        raise ValueError(f\"{path} lineup_data is missing columns: {missing}\")\n",
    "\n",
    "    df = df.copy()\n",
    "    df[\"Year\"] = int(year)\n",
    "    df[\"Player_norm\"] = df[\"Player\"].map(normalize_player_name)\n",
    "    df[\"League_ID\"] = df[\"League_ID\"].astype(int)\n",
    "    df[\"Year\"] = df[\"Year\"].astype(int)\n",
    "    df[\"Week\"] = pd.to_numeric(df[\"Week\"], errors=\"coerce\")\n",
    "    df[\"Points\"] = pd.to_numeric(df[\"Points\"], errors=\"coerce\")\n",
    "    df[\"Slot\"] = df[\"Slot\"].astype(str).str.strip()\n",
    "    if \"Is_Starter\" in df.columns:\n",
    "        df[\"Is_Starter\"] = pd.to_numeric(df[\"Is_Starter\"], errors=\"coerce\")\n",
    "    return df\n",
    "\n",
    "def load_multi_season(raw_base: Path) -> tuple[pd.DataFrame, pd.DataFrame]:\n",
    "    draft_parts = []\n",
    "    lineup_parts = []\n",
    "\n",
    "    for year_dir in sorted([p for p in raw_base.iterdir() if p.is_dir() and p.name.isdigit() and len(p.name) == 4]):\n",
    "        year = int(year_dir.name)\n",
    "\n",
    "        dpath = year_dir / \"draft_data.csv\"\n",
    "        lpath = year_dir / \"lineup_data.csv\"\n",
    "\n",
    "        if dpath.exists():\n",
    "            draft_parts.append(load_draft(dpath, year))\n",
    "        else:\n",
    "            print(f\"Skipping {year}: missing {dpath}\")\n",
    "\n",
    "        if lpath.exists():\n",
    "            lineup_parts.append(load_lineups(lpath, year))\n",
    "        else:\n",
    "            print(f\"Skipping {year}: missing {lpath}\")\n",
    "\n",
    "    if not draft_parts:\n",
    "        raise FileNotFoundError(f\"No draft_data.csv found under {raw_base}/<YEAR>/draft_data.csv\")\n",
    "    if not lineup_parts:\n",
    "        raise FileNotFoundError(f\"No lineup_data.csv found under {raw_base}/<YEAR>/lineup_data.csv\")\n",
    "\n",
    "    draft_all = pd.concat(draft_parts, ignore_index=True)\n",
    "    lineups_all = pd.concat(lineup_parts, ignore_index=True)\n",
    "    return draft_all, lineups_all\n",
    "\n",
    "\n",
    "draft_raw, lineups_raw = load_multi_season(RAW_BASE)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7738c638",
   "metadata": {},
   "outputs": [],
   "source": [
    "# ============================================================\n",
    "# BLOCK 4 — BASIC DRAFT METADATA\n",
    "# ============================================================\n",
    "\n",
    "def add_draft_length(draft_df: pd.DataFrame) -> pd.DataFrame:\n",
    "    out = draft_df.copy()\n",
    "    out[\"Draft_Length\"] = (\n",
    "        out.groupby([\"League_ID\", \"Year\"], dropna=False)[\"Overall\"]\n",
    "          .transform(\"max\")\n",
    "    )\n",
    "    out[\"Draft_Length\"] = pd.to_numeric(out[\"Draft_Length\"], errors=\"coerce\").fillna(-1).astype(int)\n",
    "    return out\n",
    "\n",
    "draft_raw = add_draft_length(draft_raw)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2885cece",
   "metadata": {},
   "outputs": [],
   "source": [
    "# ============================================================\n",
    "# BLOCK 5 — FILTER #1: STANDARD STARTER SIGNATURE (league-year)\n",
    "# ============================================================\n",
    "\n",
    "def infer_league_starter_signature(lineups: pd.DataFrame) -> pd.DataFrame:\n",
    "    df = lineups.copy()\n",
    "    required = {\"League_ID\",\"Year\",\"Team\",\"Week\",\"Slot\",\"Is_Starter\"}\n",
    "    missing = required - set(df.columns)\n",
    "    if missing:\n",
    "        raise ValueError(f\"lineups missing columns for starter signature: {sorted(missing)}\")\n",
    "\n",
    "    df[\"Slot_norm\"] = df[\"Slot\"].map(normalize_slot)\n",
    "    starters = df[df[\"Is_Starter\"].fillna(0).astype(int) == 1].copy()\n",
    "\n",
    "    tw = (\n",
    "        starters.groupby([\"League_ID\",\"Year\",\"Team\",\"Week\",\"Slot_norm\"])\n",
    "        .size()\n",
    "        .reset_index(name=\"n\")\n",
    "    )\n",
    "\n",
    "    pivot = (\n",
    "        tw.pivot_table(\n",
    "            index=[\"League_ID\",\"Year\",\"Team\",\"Week\"],\n",
    "            columns=\"Slot_norm\",\n",
    "            values=\"n\",\n",
    "            aggfunc=\"sum\",\n",
    "            fill_value=0,\n",
    "        )\n",
    "        .reset_index()\n",
    "    )\n",
    "\n",
    "    for col in [\"QB\",\"RB\",\"WR\",\"TE\",\"K\",\"D/ST\",\"FLEX\",\"OP\"]:\n",
    "        if col not in pivot.columns:\n",
    "            pivot[col] = 0\n",
    "\n",
    "    pivot[\"Starters_Total\"] = pivot[[\"QB\",\"RB\",\"WR\",\"TE\",\"K\",\"D/ST\",\"FLEX\",\"OP\"]].sum(axis=1)\n",
    "\n",
    "    def mode_int(s: pd.Series) -> int:\n",
    "        vc = s.value_counts()\n",
    "        return int(vc.index[0]) if len(vc) else 0\n",
    "\n",
    "    league_sig = (\n",
    "        pivot.groupby([\"League_ID\",\"Year\"], dropna=False)\n",
    "        .agg(\n",
    "            QB=(\"QB\", mode_int),\n",
    "            RB=(\"RB\", mode_int),\n",
    "            WR=(\"WR\", mode_int),\n",
    "            TE=(\"TE\", mode_int),\n",
    "            K=(\"K\", mode_int),\n",
    "            DST=(\"D/ST\", mode_int),\n",
    "            FLEX=(\"FLEX\", mode_int),\n",
    "            OP=(\"OP\", mode_int),\n",
    "            Starters_Total=(\"Starters_Total\", mode_int),\n",
    "        )\n",
    "        .reset_index()\n",
    "    )\n",
    "\n",
    "    league_sig[\"Signature\"] = (\n",
    "        \"QB=\" + league_sig[\"QB\"].astype(str) +\n",
    "        \",RB=\" + league_sig[\"RB\"].astype(str) +\n",
    "        \",WR=\" + league_sig[\"WR\"].astype(str) +\n",
    "        \",TE=\" + league_sig[\"TE\"].astype(str) +\n",
    "        \",FLEX=\" + league_sig[\"FLEX\"].astype(str) +\n",
    "        \",K=\" + league_sig[\"K\"].astype(str) +\n",
    "        \",DST=\" + league_sig[\"DST\"].astype(str) +\n",
    "        \",OP=\" + league_sig[\"OP\"].astype(str) +\n",
    "        \",START=\" + league_sig[\"Starters_Total\"].astype(str)\n",
    "    )\n",
    "    return league_sig\n",
    "\n",
    "def filter_standard_leagues(\n",
    "    draft: pd.DataFrame,\n",
    "    lineups: pd.DataFrame,\n",
    "    *,\n",
    "    expected: dict[str, int] | None = None,\n",
    "    verbose: bool = True\n",
    ") -> tuple[pd.DataFrame, pd.DataFrame, pd.DataFrame]:\n",
    "    if expected is None:\n",
    "        expected = {\"QB\":1, \"RB\":2, \"WR\":2, \"TE\":1, \"FLEX\":1, \"K\":1, \"D/ST\":1, \"OP\":0, \"STARTERS\":9}\n",
    "\n",
    "    league_sig = infer_league_starter_signature(lineups)\n",
    "\n",
    "    keep = (\n",
    "        (league_sig[\"QB\"] == expected[\"QB\"]) &\n",
    "        (league_sig[\"RB\"] == expected[\"RB\"]) &\n",
    "        (league_sig[\"WR\"] == expected[\"WR\"]) &\n",
    "        (league_sig[\"TE\"] == expected[\"TE\"]) &\n",
    "        (league_sig[\"FLEX\"] == expected[\"FLEX\"]) &\n",
    "        (league_sig[\"K\"] == expected[\"K\"]) &\n",
    "        (league_sig[\"DST\"] == expected[\"D/ST\"]) &\n",
    "        (league_sig[\"OP\"] == expected[\"OP\"]) &\n",
    "        (league_sig[\"Starters_Total\"] == expected[\"STARTERS\"])\n",
    "    )\n",
    "    league_sig[\"Keep_Standard\"] = keep\n",
    "\n",
    "    kept = league_sig[league_sig[\"Keep_Standard\"]][[\"League_ID\",\"Year\"]]\n",
    "    draft_filt  = draft.merge(kept, on=[\"League_ID\",\"Year\"], how=\"inner\")\n",
    "    lineups_filt = lineups.merge(kept, on=[\"League_ID\",\"Year\"], how=\"inner\")\n",
    "\n",
    "    if verbose:\n",
    "        total = len(league_sig)\n",
    "        k = int(league_sig[\"Keep_Standard\"].sum())\n",
    "        print(f\"[filter_standard_leagues] keeping {k}/{total} league-years ({k/total:.1%})\")\n",
    "        if total - k > 0:\n",
    "            print(\"[filter_standard_leagues] top non-standard signatures:\")\n",
    "            print(league_sig.loc[~league_sig[\"Keep_Standard\"], \"Signature\"].value_counts().head(10))\n",
    "\n",
    "    return draft_filt, lineups_filt, league_sig\n",
    "\n",
    "\n",
    "draft_std, lineups_std, league_sig = filter_standard_leagues(\n",
    "    draft_raw, lineups_raw,\n",
    "    expected=EXPECTED_STARTERS,\n",
    "    verbose=True\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "82109a18",
   "metadata": {},
   "outputs": [],
   "source": [
    "# ============================================================\n",
    "# BLOCK 6 — FILTER #2: SCORING-RULE FILTER USING ANCHOR PLAYERS (league-year)\n",
    "# ============================================================\n",
    "\n",
    "def _season_points_by_league_year(lineups: pd.DataFrame) -> pd.DataFrame:\n",
    "    df = lineups.copy()\n",
    "    df[\"Points\"] = pd.to_numeric(df[\"Points\"], errors=\"coerce\")\n",
    "    return (\n",
    "        df.groupby([\"League_ID\",\"Year\",\"Player_norm\"], dropna=False)[\"Points\"]\n",
    "          .sum(min_count=1)\n",
    "          .reset_index()\n",
    "          .rename(columns={\"Points\":\"Season_Total_Points\"})\n",
    "    )\n",
    "\n",
    "def filter_scoring_rule_outliers(\n",
    "    draft: pd.DataFrame,\n",
    "    lineups: pd.DataFrame,\n",
    "    *,\n",
    "    anchors_by_pos: dict[str, list[str]] | None = None,\n",
    "    z_thresh: float = 3.5,\n",
    "    min_anchors_hit: int = 4,\n",
    "    verbose: bool = True\n",
    ") -> tuple[pd.DataFrame, pd.DataFrame, pd.DataFrame]:\n",
    "    \"\"\"\n",
    "    Goal: remove league-years with strange scoring rules.\n",
    "    Method:\n",
    "      - compute Season_Total_Points per (League_ID, Year, Player_norm)\n",
    "      - for each position group, look at anchor player season totals across league-years\n",
    "      - compute robust z-score via median/MAD per (Year, anchor)\n",
    "      - mark league-year as outlier if too many anchors are extreme\n",
    "    Notes:\n",
    "      - This is intentionally simple + robust.\n",
    "      - Works even if you don't have explicit scoring settings.\n",
    "    \"\"\"\n",
    "    if anchors_by_pos is None:\n",
    "        anchors_by_pos = ANCHORS_BY_POS\n",
    "\n",
    "    # build season totals\n",
    "    pts = _season_points_by_league_year(lineups)\n",
    "\n",
    "    # build anchor table\n",
    "    anchor_rows = []\n",
    "    for pos, names in anchors_by_pos.items():\n",
    "        for n in names:\n",
    "            anchor_rows.append((pos, normalize_player_name(n)))\n",
    "    anchors = pd.DataFrame(anchor_rows, columns=[\"AnchorPos\",\"Player_norm\"]).drop_duplicates()\n",
    "\n",
    "    # join to season totals\n",
    "    a = pts.merge(anchors, on=\"Player_norm\", how=\"inner\")\n",
    "    if a.empty:\n",
    "        meta = pd.DataFrame(columns=[\"League_ID\",\"Year\",\"Anchors_Hit\",\"Anchors_Outlier\",\"Drop\"])\n",
    "        return draft, lineups, meta\n",
    "\n",
    "    # robust z per (Year, Player_norm)\n",
    "    def robust_z(s: pd.Series) -> pd.Series:\n",
    "        x = s.astype(float)\n",
    "        med = np.nanmedian(x)\n",
    "        mad = np.nanmedian(np.abs(x - med))\n",
    "        if mad == 0 or np.isnan(mad):\n",
    "            return (x - med) * 0.0\n",
    "        return 0.6745 * (x - med) / mad  # ~ std units for normal\n",
    "\n",
    "    a[\"rz\"] = a.groupby([\"Year\",\"Player_norm\"], dropna=False)[\"Season_Total_Points\"].transform(robust_z)\n",
    "    a[\"Is_Outlier\"] = a[\"rz\"].abs() >= z_thresh\n",
    "\n",
    "    # league-year summary\n",
    "    meta = (\n",
    "        a.groupby([\"League_ID\",\"Year\"], dropna=False)\n",
    "         .agg(\n",
    "            Anchors_Hit=(\"Player_norm\",\"nunique\"),\n",
    "            AnchorRows=(\"Player_norm\",\"size\"),\n",
    "            Anchors_Outlier=(\"Is_Outlier\",\"sum\"),\n",
    "            MaxAbsRZ=(\"rz\", lambda s: float(np.nanmax(np.abs(s.to_numpy()))) if len(s) else np.nan),\n",
    "         )\n",
    "         .reset_index()\n",
    "    )\n",
    "\n",
    "    # drop if: too many outliers OR not enough anchors observed\n",
    "    meta[\"Drop\"] = (meta[\"Anchors_Hit\"] < min_anchors_hit) | (meta[\"Anchors_Outlier\"] >= 1)\n",
    "\n",
    "    kept = meta[~meta[\"Drop\"]][[\"League_ID\",\"Year\"]]\n",
    "    draft_filt = draft.merge(kept, on=[\"League_ID\",\"Year\"], how=\"inner\")\n",
    "    lineups_filt = lineups.merge(kept, on=[\"League_ID\",\"Year\"], how=\"inner\")\n",
    "\n",
    "    if verbose:\n",
    "        total = meta.shape[0]\n",
    "        kept_n = kept.shape[0]\n",
    "        print(f\"[filter_scoring_rule_outliers] keeping {kept_n}/{total} league-years ({kept_n/total:.1%})\")\n",
    "        if total - kept_n > 0:\n",
    "            print(\"[filter_scoring_rule_outliers] examples of dropped league-years:\")\n",
    "            print(meta[meta[\"Drop\"]].sort_values([\"Anchors_Hit\",\"Anchors_Outlier\",\"MaxAbsRZ\"], ascending=[True,False,False]).head(10))\n",
    "\n",
    "    return draft_filt, lineups_filt, meta\n",
    "\n",
    "\n",
    "draft_filt, lineups_filt, scoring_meta = filter_scoring_rule_outliers(\n",
    "    draft_std, lineups_std,\n",
    "    z_thresh=3.5,\n",
    "    min_anchors_hit=4,\n",
    "    verbose=True\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5fe51b04",
   "metadata": {},
   "outputs": [],
   "source": [
    "# ============================================================\n",
    "# BLOCK 7 — OPTIONAL FILTER #3: DRAFT LENGTH (league-year)\n",
    "# ============================================================\n",
    "\n",
    "def filter_draft_length(draft: pd.DataFrame, lineups: pd.DataFrame, *, length: int, verbose: bool = True):\n",
    "    d = draft.copy()\n",
    "    if \"Draft_Length\" not in d.columns:\n",
    "        d = add_draft_length(d)\n",
    "\n",
    "    kept = (\n",
    "        d.groupby([\"League_ID\",\"Year\"], dropna=False)[\"Draft_Length\"]\n",
    "         .max()\n",
    "         .reset_index()\n",
    "    )\n",
    "    kept = kept[kept[\"Draft_Length\"] == int(length)][[\"League_ID\",\"Year\"]]\n",
    "\n",
    "    d2 = d.merge(kept, on=[\"League_ID\",\"Year\"], how=\"inner\")\n",
    "    l2 = lineups.merge(kept, on=[\"League_ID\",\"Year\"], how=\"inner\")\n",
    "\n",
    "    if verbose:\n",
    "        total = d.groupby([\"League_ID\",\"Year\"]).ngroups\n",
    "        kept_n = kept.shape[0]\n",
    "        print(f\"[filter_draft_length] keeping {kept_n}/{total} league-years ({kept_n/total:.1%}) with Draft_Length={length}\")\n",
    "\n",
    "    return d2, l2\n",
    "\n",
    "\n",
    "draft_filt, lineups_filt = filter_draft_length(\n",
    "    draft_filt, lineups_filt,\n",
    "    length=EXPECTED_DRAFT_LENGTH,\n",
    "    verbose=True\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1dae00f8",
   "metadata": {},
   "outputs": [],
   "source": [
    "# ============================================================\n",
    "# BLOCK 8 — ENRICHMENT: POSITION + SEASON TOTAL POINTS (simple)\n",
    "# ============================================================\n",
    "\n",
    "def infer_position_from_slots(lineups: pd.DataFrame) -> pd.DataFrame:\n",
    "    x = lineups.copy()\n",
    "    x[\"Slot_norm\"] = x[\"Slot\"].map(normalize_slot)\n",
    "    x[\"Is_core_pos\"] = x[\"Slot_norm\"].isin({\"QB\",\"RB\",\"WR\",\"TE\",\"K\",\"D/ST\"})\n",
    "\n",
    "    counts = (\n",
    "        x.groupby([\"League_ID\",\"Year\",\"Player_norm\",\"Slot_norm\",\"Is_core_pos\"], dropna=False)\n",
    "         .size().reset_index(name=\"n\")\n",
    "         .sort_values(by=[\"League_ID\",\"Year\",\"Player_norm\",\"Is_core_pos\",\"n\"],\n",
    "                      ascending=[True,True,True,False,False])\n",
    "    )\n",
    "\n",
    "    top = (\n",
    "        counts.drop_duplicates(subset=[\"League_ID\",\"Year\",\"Player_norm\"])\n",
    "              .rename(columns={\"Slot_norm\":\"Position\"})[[\"League_ID\",\"Year\",\"Player_norm\",\"Position\"]]\n",
    "    )\n",
    "    return top\n",
    "\n",
    "def season_points_from_lineups(lineups: pd.DataFrame) -> pd.DataFrame:\n",
    "    df = lineups.copy()\n",
    "    df[\"Points\"] = pd.to_numeric(df[\"Points\"], errors=\"coerce\")\n",
    "    return (\n",
    "        df.groupby([\"League_ID\",\"Year\",\"Player_norm\"], dropna=False)[\"Points\"]\n",
    "          .sum(min_count=1)\n",
    "          .reset_index()\n",
    "          .rename(columns={\"Points\":\"Season_Total_Points\"})\n",
    "    )\n",
    "\n",
    "def build_draft_enriched(draft: pd.DataFrame, lineups: pd.DataFrame) -> pd.DataFrame:\n",
    "    d = draft.copy()\n",
    "    d[\"Player_norm\"] = d[\"Player_norm\"].map(normalize_player_name)\n",
    "\n",
    "    pos = infer_position_from_slots(lineups)\n",
    "    pts = season_points_from_lineups(lineups)\n",
    "\n",
    "    out = d.merge(pos, on=[\"League_ID\",\"Year\",\"Player_norm\"], how=\"left\")\n",
    "    out = out.merge(pts, on=[\"League_ID\",\"Year\",\"Player_norm\"], how=\"left\")\n",
    "\n",
    "    out[\"Season_Total_Points\"] = pd.to_numeric(out[\"Season_Total_Points\"], errors=\"coerce\").fillna(0.0)\n",
    "\n",
    "    # keep a clean set of columns\n",
    "    cols = [\n",
    "        \"League_ID\",\"Year\",\"Team\",\"Player\",\n",
    "        \"Round\",\"Pick\",\"Overall\",\n",
    "        \"Draft_Length\",\n",
    "        \"Position\",\"Season_Total_Points\",\n",
    "        \"Is_Autodrafted\",\"Auto_Draft_Type_ID\",\n",
    "        \"Player_norm\",\n",
    "    ]\n",
    "    for c in cols:\n",
    "        if c not in out.columns:\n",
    "            out[c] = np.nan\n",
    "    return out[cols].copy()\n",
    "\n",
    "\n",
    "draft_enriched = build_draft_enriched(draft_filt, lineups_filt)\n",
    "draft_enriched_path = OUT_DIR / \"draft_enriched_filtered.csv\"\n",
    "draft_enriched.to_csv(draft_enriched_path, index=False)\n",
    "print(f\"[saved] {draft_enriched_path} ({len(draft_enriched):,} rows)\")\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c5d1bd0d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# ============================================================\n",
    "# BLOCK 9 — OPTIMAL STARTABLE POINTS (“VALID POINTS”) PIPELINE\n",
    "#   (your slow-but-correct approach, cleaned up)\n",
    "# ============================================================\n",
    "\n",
    "def _normalize_slot_defense(slot: str) -> str:\n",
    "    slot = str(slot).strip()\n",
    "    return {\"DST\": \"D/ST\", \"DEF\": \"D/ST\"}.get(slot, slot)\n",
    "\n",
    "def infer_player_position_by_core_starts(lineups: pd.DataFrame) -> pd.DataFrame:\n",
    "    CORE = {\"QB\", \"RB\", \"WR\", \"TE\", \"K\", \"D/ST\"}\n",
    "    df = lineups.copy()\n",
    "    df[\"Slot\"] = df[\"Slot\"].map(_normalize_slot_defense)\n",
    "\n",
    "    if \"Year\" not in df.columns:\n",
    "        raise ValueError(\"lineups must include a 'Year' column for multi-season processing.\")\n",
    "\n",
    "    core_rows = df[df[\"Slot\"].isin(CORE)].copy()\n",
    "    if core_rows.empty:\n",
    "        raise ValueError(\"No core slots found in lineup_data Slot column (QB/RB/WR/TE/K/DST).\")\n",
    "\n",
    "    pos = (\n",
    "        core_rows.groupby([\"League_ID\", \"Year\", \"Team\", \"Player_norm\"])[\"Slot\"]\n",
    "        .agg(lambda s: s.value_counts().index[0])\n",
    "        .reset_index()\n",
    "        .rename(columns={\"Slot\": \"Position\"})\n",
    "    )\n",
    "    return pos\n",
    "\n",
    "def build_player_week_points(lineups: pd.DataFrame) -> pd.DataFrame:\n",
    "    df = lineups.copy()\n",
    "    df[\"Slot\"] = df[\"Slot\"].map(_normalize_slot_defense)\n",
    "    df[\"Points\"] = pd.to_numeric(df[\"Points\"], errors=\"coerce\").fillna(0.0)\n",
    "\n",
    "    if \"Year\" not in df.columns:\n",
    "        raise ValueError(\"lineups must include a 'Year' column for multi-season processing.\")\n",
    "\n",
    "    pw = (\n",
    "        df.groupby([\"League_ID\", \"Year\", \"Team\", \"Week\", \"Player_norm\"], dropna=False)[\"Points\"]\n",
    "        .max()\n",
    "        .reset_index()\n",
    "        .rename(columns={\"Points\": \"WeekPoints\"})\n",
    "    )\n",
    "    return pw\n",
    "\n",
    "def choose_optimal_lineup_for_group(\n",
    "    g: pd.DataFrame,\n",
    "    slot_counts: dict[str,int],\n",
    "    flex_eligible: set[str]\n",
    ") -> pd.DataFrame:\n",
    "    g = g.copy()\n",
    "    g[\"SelectedOptimal\"] = False\n",
    "    used = set()\n",
    "\n",
    "    def select_top(pos, n):\n",
    "        nonlocal used\n",
    "        if n <= 0:\n",
    "            return []\n",
    "        cand = g[(g[\"Position\"] == pos) & (~g[\"Player_norm\"].isin(used))].sort_values(\"WeekPoints\", ascending=False)\n",
    "        chosen = cand.head(n)[\"Player_norm\"].tolist()\n",
    "        used.update(chosen)\n",
    "        return chosen\n",
    "\n",
    "    def select_flex(n):\n",
    "        nonlocal used\n",
    "        if n <= 0:\n",
    "            return []\n",
    "        cand = g[(g[\"Position\"].isin(flex_eligible)) & (~g[\"Player_norm\"].isin(used))].sort_values(\"WeekPoints\", ascending=False)\n",
    "        chosen = cand.head(n)[\"Player_norm\"].tolist()\n",
    "        used.update(chosen)\n",
    "        return chosen\n",
    "\n",
    "    selected = []\n",
    "    for pos in [\"QB\", \"RB\", \"WR\", \"TE\", \"K\", \"D/ST\"]:\n",
    "        selected += select_top(pos, slot_counts.get(pos, 0))\n",
    "    selected += select_flex(slot_counts.get(\"FLEX\", 0))\n",
    "\n",
    "    g.loc[g[\"Player_norm\"].isin(selected), \"SelectedOptimal\"] = True\n",
    "    return g\n",
    "\n",
    "def compute_optimal_startable_points(\n",
    "    lineups: pd.DataFrame,\n",
    "    *,\n",
    "    slot_counts: dict[str,int] | None = None,\n",
    "    flex_eligible: set[str] | None = None,\n",
    "    status_every: int = 250\n",
    ") -> pd.DataFrame:\n",
    "    if slot_counts is None:\n",
    "        slot_counts = {\"QB\":1, \"RB\":2, \"WR\":2, \"TE\":1, \"FLEX\":1, \"K\":1, \"D/ST\":1}\n",
    "    if flex_eligible is None:\n",
    "        flex_eligible = {\"RB\",\"WR\",\"TE\"}\n",
    "\n",
    "    t_all = time.time()\n",
    "    print(\"[compute_optimal_startable_points] start\", flush=True)\n",
    "\n",
    "    df = lineups.copy()\n",
    "    df[\"Player_norm\"] = df[\"Player_norm\"] if \"Player_norm\" in df.columns else df[\"Player\"].astype(str).str.strip()\n",
    "    df[\"Slot\"] = df[\"Slot\"].map(_normalize_slot_defense)\n",
    "\n",
    "    if \"Year\" not in df.columns:\n",
    "        raise ValueError(\"lineups must include a 'Year' column for multi-season processing.\")\n",
    "\n",
    "    print(f\"[compute_optimal_startable_points] rows: {len(df):,}\", flush=True)\n",
    "\n",
    "    pos = infer_player_position_by_core_starts(df)\n",
    "    pw = build_player_week_points(df)\n",
    "\n",
    "    pw = pw.merge(pos, on=[\"League_ID\",\"Year\",\"Team\",\"Player_norm\"], how=\"left\")\n",
    "    pw[\"Position\"] = pw[\"Position\"].fillna(\"UNKNOWN\")\n",
    "\n",
    "    gb = pw.groupby([\"League_ID\",\"Year\",\"Team\",\"Week\"], sort=False)\n",
    "    n_groups = gb.ngroups\n",
    "    print(f\"[compute_optimal_startable_points] optimizing {n_groups:,} team-weeks...\", flush=True)\n",
    "\n",
    "    t0 = time.time()\n",
    "    selected_parts = []\n",
    "    for i, (_, g) in enumerate(gb, start=1):\n",
    "        if i % status_every == 0 or i == 1 or i == n_groups:\n",
    "            elapsed = time.time() - t0\n",
    "            rate = i / elapsed if elapsed > 0 else float(\"inf\")\n",
    "            print(f\"  - progress: {i:,}/{n_groups:,} groups ({rate:.1f} groups/s)\", flush=True)\n",
    "        selected_parts.append(choose_optimal_lineup_for_group(g, slot_counts, flex_eligible))\n",
    "\n",
    "    selected = pd.concat(selected_parts, ignore_index=True)\n",
    "    print(f\"[compute_optimal_startable_points] done in {time.time()-t_all:.2f}s\", flush=True)\n",
    "    return selected\n",
    "\n",
    "def add_season_total_points_valid(\n",
    "    draft_enriched: pd.DataFrame,\n",
    "    optimal_selected: pd.DataFrame\n",
    ") -> pd.DataFrame:\n",
    "    for col in [\"Year\", \"League_ID\", \"Team\", \"Player_norm\"]:\n",
    "        if col not in draft_enriched.columns:\n",
    "            raise ValueError(f\"draft_enriched missing required column '{col}' for multi-season merge.\")\n",
    "    if \"Year\" not in optimal_selected.columns:\n",
    "        raise ValueError(\"optimal_selected missing 'Year' column.\")\n",
    "\n",
    "    valid = (\n",
    "        optimal_selected[optimal_selected[\"SelectedOptimal\"]]\n",
    "        .groupby([\"League_ID\",\"Year\",\"Team\",\"Player_norm\"], dropna=False)[\"WeekPoints\"]\n",
    "        .sum()\n",
    "        .reset_index()\n",
    "        .rename(columns={\"WeekPoints\":\"Season_Total_Points_Valid\"})\n",
    "    )\n",
    "\n",
    "    out = draft_enriched.merge(valid, on=[\"League_ID\",\"Year\",\"Team\",\"Player_norm\"], how=\"left\")\n",
    "    out[\"Season_Total_Points_Valid\"] = pd.to_numeric(out[\"Season_Total_Points_Valid\"], errors=\"coerce\").fillna(0.0)\n",
    "    return out\n",
    "\n",
    "\n",
    "optimal_selected = compute_optimal_startable_points(\n",
    "    lineups_filt,\n",
    "    slot_counts={\"QB\":1,\"RB\":2,\"WR\":2,\"TE\":1,\"FLEX\":1,\"K\":1,\"D/ST\":1},\n",
    "    flex_eligible={\"RB\",\"WR\",\"TE\"},\n",
    "    status_every=250\n",
    ")\n",
    "\n",
    "draft_with_valid = add_season_total_points_valid(draft_enriched, optimal_selected)\n",
    "draft_with_valid_path = OUT_DIR / \"draft_with_valid_points_filtered.csv\"\n",
    "draft_with_valid.to_csv(draft_with_valid_path, index=False)\n",
    "print(f\"[saved] {draft_with_valid_path} ({len(draft_with_valid):,} rows)\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "09b893cf",
   "metadata": {},
   "outputs": [],
   "source": [
    "# ============================================================\n",
    "# BLOCK 10 — FULLY AUTODRAFTED TEAMS + SANITY CHECK (1.01 variety)\n",
    "# ============================================================\n",
    "\n",
    "def identify_fully_autodrafted_teams(\n",
    "    draft_df: pd.DataFrame,\n",
    "    *,\n",
    "    sanity_check_pick1: bool = True,\n",
    "    verbose: bool = True\n",
    ") -> pd.DataFrame:\n",
    "    required = [\"League_ID\", \"Year\", \"Team\", \"Is_Autodrafted\"]\n",
    "    missing = [c for c in required if c not in draft_df.columns]\n",
    "    if missing:\n",
    "        raise ValueError(f\"draft_df missing columns: {missing}\")\n",
    "\n",
    "    result = (\n",
    "        draft_df\n",
    "        .groupby([\"League_ID\", \"Year\", \"Team\"], dropna=False)\n",
    "        .agg(\n",
    "            Total_Picks=(\"Is_Autodrafted\", \"size\"),\n",
    "            Autodrafted_Picks=(\"Is_Autodrafted\", \"sum\")\n",
    "        )\n",
    "        .reset_index()\n",
    "    )\n",
    "    result[\"Is_Fully_Autodrafted\"] = (result[\"Total_Picks\"] == result[\"Autodrafted_Picks\"])\n",
    "\n",
    "    if sanity_check_pick1:\n",
    "        for c in [\"Overall\", \"Player_norm\"]:\n",
    "            if c not in draft_df.columns:\n",
    "                raise ValueError(f\"Sanity check requires column '{c}'\")\n",
    "\n",
    "        df_auto = draft_df.merge(\n",
    "            result[[\"League_ID\", \"Year\", \"Team\", \"Is_Fully_Autodrafted\"]],\n",
    "            on=[\"League_ID\", \"Year\", \"Team\"],\n",
    "            how=\"left\"\n",
    "        )\n",
    "\n",
    "        pick1 = df_auto[(df_auto[\"Is_Fully_Autodrafted\"]) & (df_auto[\"Overall\"] == 1)]\n",
    "        if verbose:\n",
    "            print(\"\\n[Sanity Check] Fully-Autodrafted 1.01 Picks\")\n",
    "            if pick1.empty:\n",
    "                print(\"  none found\")\n",
    "            else:\n",
    "                summary = (pick1.groupby(\"Year\")[\"Player_norm\"]\n",
    "                           .agg(Unique_1OA=\"nunique\", Total_1OA=\"count\")\n",
    "                           .reset_index())\n",
    "                print(summary.to_string(index=False))\n",
    "                print(f\"\\nAcross all years:\\n  Total 1.01 picks = {len(pick1)}\\n  Unique players  = {pick1['Player_norm'].nunique()}\")\n",
    "\n",
    "    return result\n",
    "\n",
    "\n",
    "fully_auto = identify_fully_autodrafted_teams(draft_with_valid, sanity_check_pick1=True, verbose=True)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c8a2d034",
   "metadata": {},
   "outputs": [],
   "source": [
    "# ============================================================\n",
    "# BLOCK 11 — TEAM TOTAL VALID POINTS DISTRIBUTIONS\n",
    "# ============================================================\n",
    "\n",
    "def team_total_valid_points(draft_with_valid: pd.DataFrame, *, fully_autodraft_only: bool | None = None) -> pd.DataFrame:\n",
    "    required = [\"League_ID\", \"Year\", \"Team\", \"Is_Autodrafted\", \"Season_Total_Points_Valid\"]\n",
    "    missing = [c for c in required if c not in draft_with_valid.columns]\n",
    "    if missing:\n",
    "        raise ValueError(f\"draft_with_valid missing columns: {missing}\")\n",
    "\n",
    "    df = draft_with_valid.copy()\n",
    "\n",
    "    team_auto = (\n",
    "        df.groupby([\"League_ID\", \"Year\", \"Team\"], dropna=False)[\"Is_Autodrafted\"]\n",
    "          .agg(Total_Picks=\"size\", Autodrafted_Picks=\"sum\")\n",
    "          .reset_index()\n",
    "    )\n",
    "    team_auto[\"Is_Fully_Autodrafted\"] = team_auto[\"Total_Picks\"].eq(team_auto[\"Autodrafted_Picks\"])\n",
    "    df = df.merge(team_auto[[\"League_ID\", \"Year\", \"Team\", \"Is_Fully_Autodrafted\"]],\n",
    "                  on=[\"League_ID\", \"Year\", \"Team\"], how=\"left\")\n",
    "\n",
    "    if fully_autodraft_only is True:\n",
    "        df = df[df[\"Is_Fully_Autodrafted\"]].copy()\n",
    "    elif fully_autodraft_only is False:\n",
    "        df = df[~df[\"Is_Fully_Autodrafted\"]].copy()\n",
    "\n",
    "    team_totals = (\n",
    "        df.groupby([\"League_ID\", \"Year\", \"Team\"], dropna=False)[\"Season_Total_Points_Valid\"]\n",
    "          .sum()\n",
    "          .reset_index()\n",
    "          .rename(columns={\"Season_Total_Points_Valid\": \"Total_Valid_Points\"})\n",
    "          .sort_values(\"Total_Valid_Points\", ascending=False)\n",
    "    )\n",
    "    if team_totals.empty:\n",
    "        raise ValueError(\"No teams found after filtering.\")\n",
    "    return team_totals\n",
    "\n",
    "def plot_total_valid_points_dist(team_totals: pd.DataFrame, *, bins: int = 20, title: str = \"\") -> None:\n",
    "    x = team_totals[\"Total_Valid_Points\"].astype(float).to_numpy()\n",
    "    avg = float(np.mean(x))\n",
    "    plt.figure(figsize=(10, 5))\n",
    "    plt.hist(x, bins=bins, density=True, alpha=0.6)\n",
    "    plt.axvline(avg, linestyle=\"--\")\n",
    "    plt.xlabel(\"Total Valid Points (Optimal-Start Weeks Only)\")\n",
    "    plt.ylabel(\"Density\")\n",
    "    plt.title(title or f\"Total Valid Points Distribution (n={len(x)})\")\n",
    "    ymin, ymax = plt.ylim()\n",
    "    plt.text(avg, ymax * 0.95, f\"avg = {avg:.1f}\", va=\"top\")\n",
    "    plt.tight_layout()\n",
    "    plt.show()\n",
    "    print(f\"Average Total Valid Points: {avg:.2f}\")\n",
    "\n",
    "team_totals_auto = team_total_valid_points(draft_with_valid, fully_autodraft_only=True)\n",
    "plot_total_valid_points_dist(team_totals_auto, bins=20, title=\"Autodrafted Teams: Total Valid Points Distribution\")\n",
    "\n",
    "team_totals_non = team_total_valid_points(draft_with_valid, fully_autodraft_only=False)\n",
    "plot_total_valid_points_dist(team_totals_non, bins=20, title=\"NOT 100% Autodrafted Teams: Total Valid Points Distribution\")\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "338baa72",
   "metadata": {},
   "outputs": [],
   "source": [
    "# ============================================================\n",
    "# BLOCK 12 — EXPECTED VALID POINTS BY PICK (autodraft baseline)\n",
    "# ============================================================\n",
    "\n",
    "def expected_valid_points_by_pick_autodraft_distribution(draft_with_valid: pd.DataFrame) -> pd.DataFrame:\n",
    "    required = [\"League_ID\",\"Year\",\"Team\",\"Overall\",\"Is_Autodrafted\",\"Season_Total_Points_Valid\",\"Player_norm\"]\n",
    "    missing = [c for c in required if c not in draft_with_valid.columns]\n",
    "    if missing:\n",
    "        raise ValueError(f\"Missing columns: {missing}\")\n",
    "\n",
    "    df = draft_with_valid.copy()\n",
    "\n",
    "    team_auto = (\n",
    "        df.groupby([\"League_ID\",\"Year\",\"Team\"], dropna=False)[\"Is_Autodrafted\"]\n",
    "          .agg(Total_Picks=\"size\", Auto_Picks=\"sum\")\n",
    "          .reset_index()\n",
    "    )\n",
    "    team_auto[\"Is_Fully_Autodrafted\"] = team_auto[\"Total_Picks\"].eq(team_auto[\"Auto_Picks\"])\n",
    "\n",
    "    df = df.merge(team_auto[[\"League_ID\",\"Year\",\"Team\",\"Is_Fully_Autodrafted\"]],\n",
    "                  on=[\"League_ID\",\"Year\",\"Team\"], how=\"left\")\n",
    "    df = df[df[\"Is_Fully_Autodrafted\"]].copy()\n",
    "\n",
    "    dist = (\n",
    "        df.groupby(\"Overall\", dropna=False)\n",
    "        .agg(\n",
    "            Mean=(\"Season_Total_Points_Valid\", \"mean\"),\n",
    "            Std=(\"Season_Total_Points_Valid\", \"std\"),\n",
    "            N_Picks=(\"Season_Total_Points_Valid\", \"count\"),\n",
    "            Unique_Players=(\"Player_norm\", \"nunique\"),\n",
    "            P10=(\"Season_Total_Points_Valid\", lambda s: s.quantile(0.10)),\n",
    "            P25=(\"Season_Total_Points_Valid\", lambda s: s.quantile(0.25)),\n",
    "            P50=(\"Season_Total_Points_Valid\", lambda s: s.quantile(0.50)),\n",
    "            P75=(\"Season_Total_Points_Valid\", lambda s: s.quantile(0.75)),\n",
    "            P90=(\"Season_Total_Points_Valid\", lambda s: s.quantile(0.90)),\n",
    "        )\n",
    "        .reset_index()\n",
    "        .sort_values(\"Overall\")\n",
    "    )\n",
    "    return dist"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "376378a7",
   "metadata": {},
   "outputs": [],
   "source": [
    "# ============================================================\n",
    "# BLOCK 13 — DENOISED EXPECTED CURVE (optional)\n",
    "# ============================================================\n",
    "\n",
    "def expected_valid_points_by_pick_from_autodraft_pooled_denoised(\n",
    "    draft_with_valid: pd.DataFrame,\n",
    "    *,\n",
    "    estimator: str = \"trimmed_mean\",   # \"mean\" | \"median\" | \"trimmed_mean\" | \"winsor_mean\"\n",
    "    trim: float = 0.10,\n",
    "    smooth_window: int = 5\n",
    ") -> pd.DataFrame:\n",
    "    required = [\"League_ID\",\"Year\",\"Team\",\"Overall\",\"Is_Autodrafted\",\"Season_Total_Points_Valid\"]\n",
    "    missing = [c for c in required if c not in draft_with_valid.columns]\n",
    "    if missing:\n",
    "        raise ValueError(f\"draft_with_valid missing columns: {missing}\")\n",
    "\n",
    "    df = draft_with_valid.copy()\n",
    "    df[\"Overall\"] = pd.to_numeric(df[\"Overall\"], errors=\"coerce\").astype(int)\n",
    "    df[\"Is_Autodrafted\"] = pd.to_numeric(df[\"Is_Autodrafted\"], errors=\"coerce\").fillna(0).astype(int)\n",
    "    df[\"Season_Total_Points_Valid\"] = pd.to_numeric(df[\"Season_Total_Points_Valid\"], errors=\"coerce\")\n",
    "\n",
    "    team_auto = (\n",
    "        df.groupby([\"League_ID\",\"Year\",\"Team\"], dropna=False)[\"Is_Autodrafted\"]\n",
    "          .agg(Total_Picks=\"size\", Autodrafted_Picks=\"sum\")\n",
    "          .reset_index()\n",
    "    )\n",
    "    team_auto[\"Is_Fully_Autodrafted\"] = team_auto[\"Total_Picks\"].eq(team_auto[\"Autodrafted_Picks\"])\n",
    "    df = df.merge(team_auto[[\"League_ID\",\"Year\",\"Team\",\"Is_Fully_Autodrafted\"]],\n",
    "                  on=[\"League_ID\",\"Year\",\"Team\"], how=\"left\")\n",
    "\n",
    "    df_auto = df[df[\"Is_Fully_Autodrafted\"]].copy()\n",
    "    if df_auto.empty:\n",
    "        raise ValueError(\"No fully-autodrafted teams found.\")\n",
    "\n",
    "    if estimator == \"mean\":\n",
    "        agg_func = \"mean\"\n",
    "    elif estimator == \"median\":\n",
    "        agg_func = lambda s: float(np.nanmedian(s.to_numpy()))\n",
    "    elif estimator == \"trimmed_mean\":\n",
    "        from scipy.stats import trim_mean\n",
    "        agg_func = lambda s: float(trim_mean(s.dropna().to_numpy(), proportiontocut=trim))\n",
    "    elif estimator == \"winsor_mean\":\n",
    "        from scipy.stats.mstats import winsorize\n",
    "        agg_func = lambda s: float(np.mean(winsorize(s.dropna().to_numpy(), limits=trim)))\n",
    "    else:\n",
    "        raise ValueError(\"estimator must be one of: mean, median, trimmed_mean, winsor_mean\")\n",
    "\n",
    "    pooled = (\n",
    "        df_auto.groupby(\"Overall\", dropna=False)[\"Season_Total_Points_Valid\"]\n",
    "              .agg(Expected_Valid_Points=agg_func, Std_Valid_Points=\"std\", N=\"count\")\n",
    "              .reset_index()\n",
    "              .sort_values(\"Overall\")\n",
    "    )\n",
    "\n",
    "    if smooth_window and smooth_window > 1:\n",
    "        pooled[\"Expected_Smoothed\"] = (\n",
    "            pooled[\"Expected_Valid_Points\"].rolling(window=smooth_window, center=True, min_periods=1).mean()\n",
    "        )\n",
    "    else:\n",
    "        pooled[\"Expected_Smoothed\"] = pooled[\"Expected_Valid_Points\"]\n",
    "\n",
    "    return pooled"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "44493a4a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# ============================================================\n",
    "# BLOCK 14 — SCORE PICKS (points added, z-score)\n",
    "# ============================================================\n",
    "\n",
    "def expected_valid_points_by_pick_from_autodraft(\n",
    "    draft_with_valid: pd.DataFrame,\n",
    "    *,\n",
    "    by_year: bool = True\n",
    ") -> pd.DataFrame:\n",
    "    required = [\"League_ID\",\"Year\",\"Team\",\"Overall\",\"Is_Autodrafted\",\"Season_Total_Points_Valid\"]\n",
    "    missing = [c for c in required if c not in draft_with_valid.columns]\n",
    "    if missing:\n",
    "        raise ValueError(f\"draft_with_valid missing columns: {missing}\")\n",
    "\n",
    "    df = draft_with_valid.copy()\n",
    "    df[\"Year\"] = df[\"Year\"].astype(int)\n",
    "    df[\"Overall\"] = pd.to_numeric(df[\"Overall\"], errors=\"coerce\").astype(int)\n",
    "    df[\"Is_Autodrafted\"] = pd.to_numeric(df[\"Is_Autodrafted\"], errors=\"coerce\").fillna(0).astype(int)\n",
    "    df[\"Season_Total_Points_Valid\"] = pd.to_numeric(df[\"Season_Total_Points_Valid\"], errors=\"coerce\")\n",
    "\n",
    "    team_auto = (\n",
    "        df.groupby([\"League_ID\",\"Year\",\"Team\"], dropna=False)[\"Is_Autodrafted\"]\n",
    "          .agg(Total_Picks=\"size\", Autodrafted_Picks=\"sum\")\n",
    "          .reset_index()\n",
    "    )\n",
    "    team_auto[\"Is_Fully_Autodrafted\"] = team_auto[\"Total_Picks\"].eq(team_auto[\"Autodrafted_Picks\"])\n",
    "    df = df.merge(team_auto[[\"League_ID\",\"Year\",\"Team\",\"Is_Fully_Autodrafted\"]],\n",
    "                  on=[\"League_ID\",\"Year\",\"Team\"], how=\"left\")\n",
    "\n",
    "    df_auto = df[df[\"Is_Fully_Autodrafted\"]].copy()\n",
    "    if df_auto.empty:\n",
    "        raise ValueError(\"No fully-autodrafted teams found.\")\n",
    "\n",
    "    keys = [\"Overall\"] if not by_year else [\"Year\",\"Overall\"]\n",
    "    expected = (\n",
    "        df_auto.groupby(keys, dropna=False)[\"Season_Total_Points_Valid\"]\n",
    "              .agg(Expected_Valid_Points=\"mean\", Std_Valid_Points=\"std\", N=\"count\")\n",
    "              .reset_index()\n",
    "              .sort_values(keys)\n",
    "    )\n",
    "    return expected\n",
    "\n",
    "\n",
    "expected_by_pick_year = expected_valid_points_by_pick_from_autodraft(draft_with_valid, by_year=True)\n",
    "\n",
    "draft_scored = draft_with_valid.merge(\n",
    "    expected_by_pick_year[[\"Year\",\"Overall\",\"Expected_Valid_Points\",\"Std_Valid_Points\"]],\n",
    "    on=[\"Year\",\"Overall\"],\n",
    "    how=\"left\"\n",
    ")\n",
    "draft_scored[\"Points_Added\"] = draft_scored[\"Season_Total_Points_Valid\"] - draft_scored[\"Expected_Valid_Points\"]\n",
    "draft_scored[\"Points_Added_Z\"] = draft_scored[\"Points_Added\"] / draft_scored[\"Std_Valid_Points\"]\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "31d8f5f2",
   "metadata": {},
   "outputs": [],
   "source": [
    "# ============================================================\n",
    "# BLOCK 15 — PLOTS (variance band, zoom, denoised curve)\n",
    "# ============================================================\n",
    "\n",
    "# 15A: Denoised pooled curve\n",
    "expected_by_pick_pooled = expected_valid_points_by_pick_from_autodraft_pooled_denoised(\n",
    "    draft_with_valid,\n",
    "    estimator=\"trimmed_mean\",\n",
    "    trim=0.10,\n",
    "    smooth_window=5\n",
    ")\n",
    "expected_by_pick_pooled.plot(x=\"Overall\", y=\"Expected_Smoothed\",\n",
    "                             title=\"Autodraft Expected Valid Points by Pick (All Years, Denoised)\")\n",
    "plt.show()\n",
    "\n",
    "# 15B: Distribution bands (P10–P90, P25–P75)\n",
    "dist = expected_valid_points_by_pick_autodraft_distribution(draft_with_valid)\n",
    "\n",
    "plt.plot(dist[\"Overall\"], dist[\"Mean\"], label=\"Expected (Mean)\")\n",
    "plt.fill_between(dist[\"Overall\"], dist[\"P25\"], dist[\"P75\"], alpha=0.25, label=\"25–75% range\")\n",
    "plt.fill_between(dist[\"Overall\"], dist[\"P10\"], dist[\"P90\"], alpha=0.15, label=\"10–90% range\")\n",
    "plt.xlabel(\"Overall Pick\")\n",
    "plt.ylabel(\"Valid Season Points\")\n",
    "plt.title(\"Autodraft Expected Valid Points by Pick (with Variance)\")\n",
    "plt.legend()\n",
    "plt.tight_layout()\n",
    "plt.show()\n",
    "\n",
    "# 15C: Zoom first 20 picks, annotate N (unique players + total picks)\n",
    "dist_20 = dist[dist[\"Overall\"] <= 20].copy()\n",
    "fig, ax = plt.subplots(figsize=(16, 8))\n",
    "ax.plot(dist_20[\"Overall\"], dist_20[\"Mean\"], label=\"Expected (Mean)\", linewidth=2)\n",
    "ax.fill_between(dist_20[\"Overall\"], dist_20[\"P25\"], dist_20[\"P75\"], alpha=0.30, label=\"25–75% range\")\n",
    "ax.fill_between(dist_20[\"Overall\"], dist_20[\"P10\"], dist_20[\"P90\"], alpha=0.18, label=\"10–90% range\")\n",
    "ax.set_xlabel(\"Overall Pick\", fontsize=12)\n",
    "ax.set_ylabel(\"Valid Season Points\", fontsize=12)\n",
    "ax.set_title(\"Autodraft Expected Valid Points by Pick\\nFirst 20 Picks (Variance Zoom)\", fontsize=14)\n",
    "\n",
    "for _, r in dist_20.iterrows():\n",
    "    ax.text(\n",
    "        r[\"Overall\"], r[\"P10\"] - 5,\n",
    "        f\"{int(r['Unique_Players'])} players\\n(n={int(r['N_Picks'])})\",\n",
    "        ha=\"center\", va=\"top\", fontsize=9, alpha=0.7\n",
    "    )\n",
    "\n",
    "ax.legend()\n",
    "ax.grid(alpha=0.2)\n",
    "fig.tight_layout()\n",
    "plt.show()\n",
    "\n",
    "print(expected_by_pick_pooled[[\"Overall\",\"Expected_Valid_Points\",\"Expected_Smoothed\",\"N\"]].head(10))\n",
    "print(expected_by_pick_pooled[[\"Overall\",\"Expected_Valid_Points\",\"Expected_Smoothed\",\"N\"]].tail(10))"
   ]
  }
 ],
 "metadata": {
  "language_info": {
   "name": "python"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
